{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities for working with PIL, tensor, numpy and imgaug images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.linalg import toeplitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "\n",
    "# Image\n",
    "img = torch.tensor([[1, 3, 1, 2],\n",
    "                    [0, 2, 1, 4],\n",
    "                    [2, 1, 0, 1],\n",
    "                    [3, 1, 2, 3]]).float()\n",
    "\n",
    "# Filter\n",
    "w = torch.tensor([[1, 1, 1],\n",
    "                  [1, 1, 1],\n",
    "                  [1, 1, 1]]).float()\n",
    "\n",
    "padding = 1\n",
    "kernel_size = w.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 6.,  8., 13.,  8.],\n",
      "          [ 9., 11., 15.,  9.],\n",
      "          [ 9., 12., 15., 11.],\n",
      "          [ 7.,  9.,  8.,  6.]]]], grad_fn=<ThnnConv2DBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Convolution using Pytorch\n",
    "\n",
    "conv2d = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=kernel_size, stride=1, padding=padding, \n",
    "                   bias=False, padding_mode='zeros')\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Change values in place \n",
    "    #conv2d.weight[:] = w.view(1, 1, 3, 3)\n",
    "    # Or add values as parameter\n",
    "    conv2d.weight = nn.Parameter(w.view(1, 1, 3, 3))\n",
    "    \n",
    "res_conv2d = conv2d(img[None,None])\n",
    "print(res_conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 6.,  8., 13.,  8.],\n",
      "          [ 9., 11., 15.,  9.],\n",
      "          [ 9., 12., 15., 11.],\n",
      "          [ 7.,  9.,  8.,  6.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Convolution by unfolding each image block into one column. For instance, image\n",
    "#|1 2 3|\n",
    "#|4 5 6|\n",
    "#|7 8 9|\n",
    "# with a 2x2 kernel becomes\n",
    "#|1 2 4 5|  \n",
    "#|2 3 5 6|\n",
    "#|4 5 7 8|\n",
    "#|5 6 8 9|\n",
    "# Then, convolution becomes a matrix multiplication between the unfolded image and a flattened kernel\n",
    "\n",
    "img_unf = nn.functional.unfold(img[None,None,...], (3, 3), padding=1).transpose(1, 2)\n",
    "out_unf = img_unf.matmul(w.view(-1,1))\n",
    "#out = nn.functional.fold(out_unf, (4, 4), (1, 1))  # alternative\n",
    "res_unfold = out_unf.view(1, 1, 4, 4)\n",
    "print(res_unfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6.,  8., 13.,  8.],\n",
      "        [ 9., 11., 15.,  9.],\n",
      "        [ 9., 12., 15., 11.],\n",
      "        [ 7.,  9.,  8.,  6.]])\n"
     ]
    }
   ],
   "source": [
    "# Convolution by creating a circulant matrix using the filter values\n",
    "# for a 2x2 filter\n",
    "#|1 2|\n",
    "#|3 4|\n",
    "#and a 3x3 image, the filter becomes\n",
    "#|1 2 0 3 4 0 0 0 0|\n",
    "#|0 1 2 0 3 4 0 0 0|\n",
    "#|0 0 0 1 2 0 3 4 0|\n",
    "#|0 0 0 0 1 2 0 3 4|\n",
    "# The, convolution becomes a matrix multiplication between this matrix and the flattened image\n",
    "\n",
    "H = img.shape[0]\n",
    "W = img.shape[1]\n",
    "K = kernel_size\n",
    "num_blocks_h = (H+2*padding-K+1)  # Number of filter positions in the vertical direction\n",
    "num_blocks_w = (W+2*padding-K+1)  # Number of filter positions in the horizontal direction\n",
    "num_blocks = num_blocks_h*num_blocks_w  # Number of filter positions\n",
    "\n",
    "zero_length = W+2*padding-K       # Number of zeros between rows of filter values\n",
    "first_row = torch.cat((w, torch.zeros(K,zero_length)), axis=1).view(1, -1)\n",
    "first_row = torch.cat((first_row, torch.zeros(1,(H+2*padding-K)*(W+2*padding))), axis=1)\n",
    "\n",
    "w_matrix = torch.zeros(num_blocks, first_row.numel())\n",
    "for i in range(num_blocks):\n",
    "    w_matrix[i] = first_row\n",
    "    if (i+1)%num_blocks_w==0:  # If at the end of image row\n",
    "        first_row = first_row.roll(K)\n",
    "    else:\n",
    "        first_row = first_row.roll(1)\n",
    "        \n",
    "img_column = nn.functional.pad(img, (padding, padding, padding, padding)).view(-1,1)\n",
    "res_filt_mat = w_matrix.matmul(img_column).view(img.shape)\n",
    "print(res_filt_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[11., 18., 15.],\n",
      "          [17., 27., 21.],\n",
      "          [12., 20., 15.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Calculate the gradient of the output with respect to the filter weights\n",
    "output = res_conv2d.sum()\n",
    "output.backward()\n",
    "gradients = conv2d.weight.grad\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\vec{x}$ represent the values of the padded image, $\\vec{y}$ represent the result of the convolution, $\\vec{w}$ the values of the filter and $o$ the `output` variable. We need to calculate the gradient of $o$ with respect to each weight of the filter, that is, we need\n",
    "\\begin{equation}\n",
    "\\frac{\\partial o}{\\partial \\vec{w}}\n",
    "\\end{equation}\n",
    "\n",
    "This is given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial o}{\\partial \\vec{w}} = \\frac{\\partial o}{\\partial \\vec{y}} \\frac{\\partial \\vec{y}}{\\partial \\vec{w}}\n",
    "\\end{equation}\n",
    "\n",
    "$\\frac{\\partial o}{\\partial \\vec{y}}$ is the gradient of $o$ with respect to the output image. $\\frac{\\partial \\vec{y}}{\\partial \\vec{w}}$ is the Jacobian matrix of the output with respect to the weights.\n",
    "\n",
    "As an ilustration, let's calculate $\\frac{\\partial o}{\\partial w_1}$. This is given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial o}{\\partial w_1} = \\frac{\\partial o}{\\partial \\vec{y}} \\frac{\\partial \\vec{y}}{\\partial w_1}\n",
    "\\end{equation}\n",
    "\n",
    "Since \n",
    "\n",
    "\\begin{equation}\n",
    "o = \\sum y_i\n",
    "\\end{equation}\n",
    "we have\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial o}{\\partial \\vec{y}} & = \\left( \\frac{\\partial o}{\\partial y_1},\\frac{\\partial o}{\\partial y_2},\\dots,\\frac{\\partial o}{\\partial y_n} \\right) \\\\\n",
    "& = \\left( 1, 1, \\dots, 1 \\right).\n",
    "\\end{align}\n",
    "\n",
    "For the other term of the equation, we have\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\vec{y}}{\\partial w_1} & = \\left( \\frac{\\partial y_1}{\\partial w_1},\\frac{\\partial y_2}{\\partial w_1},\\dots,\\frac{\\partial y_n}{\\partial w_1} \\right).\n",
    "\\end{align}\n",
    "For instance, $y_6$ (the value at row 2 column 2 of the result) is calculated as\n",
    "\n",
    "\\begin{equation}\n",
    "y_6 = x_8*w_1 + x_9*w_2 + x_{10}*w_3 + x_{14}*w_4 + x_{15}*w_5 + x_{16}*w_6 + x_{20}*w_7 + x_{21}*w_8 + x_{22}*w_9\n",
    "\\end{equation}\n",
    "in the convolution, and therefore\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial y_6}{\\partial w_1} = x_8.\n",
    "\\end{equation}\n",
    "\n",
    "Notice that in our notation $x_8$ corresponds to the value at row 1 and column 1 of the original image since the calculations involve some padding in the original image. Calculating the remaining values we have\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\vec{y}}{\\partial w_1} = \\left( x_1, x_2, x_3, x_4, x_7, x_8, x_9, x_{10}, x_{13}, x_{14}, x_{15}, x_{16}, x_{19}, x_{20}, x_{21}, x_{22} \\right).\n",
    "\\end{equation}\n",
    "Since we padded the image with zeros\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial \\vec{y}}{\\partial w_1} = \\left( 0, 0, 0, 0, 0, x_8, x_9, x_{10}, 0, x_{14}, x_{15}, x_{16}, 0, x_{20}, x_{21}, x_{22} \\right).\n",
    "\\end{equation}\n",
    "Thus\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial o}{\\partial w_1} = x_8 + x_9 + x_{10} + x_{14} + x_{15} + x_{16} + x_{20} + x_{21} + x_{22}.\n",
    "\\end{equation}\n",
    "\n",
    "The full Jacobian matrix is given by\n",
    "\n",
    "\\begin{equation}\n",
    "J = \n",
    "\\begin{pmatrix}\n",
    "\\frac{\\partial y_1}{\\partial w_1}    & \\frac{\\partial y_1}{\\partial w_2}    & \\dots  & \\frac{\\partial y_1}{\\partial w_9} \\\\\n",
    "\\frac{\\partial y_2}{\\partial w_1}    & \\frac{\\partial y_2}{\\partial w_2}    & \\dots  & \\frac{\\partial y_2}{\\partial w_9} \\\\\n",
    "\\vdots                               &                            \\ddots    & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial y_{16}}{\\partial w_1} & \\frac{\\partial y_{16}}{\\partial w_2} & \\dots  & \\frac{\\partial y_{16}}{\\partial w_9}\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "J = \n",
    "\\begin{pmatrix}\n",
    "x_1    & x_2    & x_3    & x_7    & x_8    & x_9    & x_{13} & x_{14} & x_{15} \\\\\n",
    "x_2    & x_3    & x_4    & x_8    & x_9    & x_{10} & x_{14} & x_{15} & x_{16} \\\\\n",
    "x_3    & x_4    & x_5    & x_9    & x_{10} & x_{11} & x_{15} & x_{16} & x_{17} \\\\\n",
    "x_4    & x_5    & x_6    & x_{10} & x_{11} & x_{12} & x_{16} & x_{17} & x_{18} \\\\\n",
    "x_7    & x_8    & x_9    & x_{13} & x_{14} & x_{15} & x_{19} & x_{20} & x_{21} \\\\\n",
    "x_8    & x_9    & x_{10} & x_{14} & x_{15} & x_{16} & x_{20} & x_{21} & x_{22} \\\\\n",
    "x_9    & x_{10} & x_{11} & x_{15} & x_{16} & x_{17} & x_{21} & x_{22} & x_{23} \\\\\n",
    "x_{10} & x_{11} & x_{12} & x_{16} & x_{17} & x_{18} & x_{22} & x_{23} & x_{24} \\\\\n",
    "x_{13} & x_{14} & x_{15} & x_{19} & x_{20} & x_{21} & x_{25} & x_{26} & x_{27} \\\\\n",
    "x_{14} & x_{15} & x_{16} & x_{20} & x_{21} & x_{22} & x_{26} & x_{27} & x_{28} \\\\\n",
    "x_{15} & x_{16} & x_{17} & x_{21} & x_{22} & x_{23} & x_{27} & x_{28} & x_{29} \\\\\n",
    "x_{16} & x_{17} & x_{18} & x_{22} & x_{23} & x_{24} & x_{28} & x_{29} & x_{30} \\\\\n",
    "x_{19} & x_{20} & x_{21} & x_{25} & x_{26} & x_{27} & x_{31} & x_{32} & x_{33} \\\\\n",
    "x_{20} & x_{21} & x_{22} & x_{26} & x_{27} & x_{28} & x_{32} & x_{33} & x_{34} \\\\\n",
    "x_{21} & x_{22} & x_{23} & x_{27} & x_{28} & x_{29} & x_{33} & x_{34} & x_{35} \\\\\n",
    "x_{22} & x_{23} & x_{24} & x_{28} & x_{29} & x_{30} & x_{34} & x_{35} & x_{36} \\\\\n",
    "\\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "But this matrix is exactly the same as `img_unf`! Thus, for convolving an image with a filter we can do\n",
    "\n",
    "\\begin{equation}\n",
    "\\vec{y} = J\\vec{w}\n",
    "\\end{equation}\n",
    "and for calculating the gradients of the output with respect to the weights we can do\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial o}{\\partial \\vec{w}} = J^T\\frac{\\partial o}{\\partial \\vec{y}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "gradients_matmul = img_unf.squeeze().T.matmul(torch.ones(res_conv2d.numel())).view(w.shape)\n",
    "print((gradients_matmul-gradients.squeeze()).abs().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[11., 18., 15.],\n",
      "        [17., 27., 21.],\n",
      "        [12., 20., 15.]])\n"
     ]
    }
   ],
   "source": [
    "# Implementing a conv2d autograd function\n",
    "\n",
    "class conv2d(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, weight, padding):\n",
    "        ctx.save_for_backward(input, weight)\n",
    "        ctx.padding = padding\n",
    "        img_unf = nn.functional.unfold(input[None,None,...], weight.shape, padding=padding).transpose(1, 2)\n",
    "        output = img_unf.matmul(weight.view(-1,1))\n",
    "        return output.view(input.shape[0]+2*padding-weight.shape[0]+1, input.shape[1]+2*padding-weight.shape[1]+1)\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, weight = ctx.saved_tensors\n",
    "        padding = ctx.padding\n",
    "        img_unf = nn.functional.unfold(input[None,None,...], weight.shape, padding=padding).transpose(1, 2)\n",
    "        gradients_matmul = img_unf.squeeze().T.matmul(grad_output.view(-1,1)).view(weight.shape)\n",
    "        #gradients_matmul = torch.ones(weight.shape)\n",
    "        return None, gradients_matmul, None\n",
    "    \n",
    "w2 = nn.Parameter(w)\n",
    "res = conv2d.apply(img, w2, 1)\n",
    "s = res.sum()\n",
    "s.backward()\n",
    "\n",
    "print(w2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
