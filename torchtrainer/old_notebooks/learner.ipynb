{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classes used for training Pytorch neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted learner.py to torchtrainer/learner.py\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Export cells\n",
    "!python notebook2script.py learner.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learner\n",
    "#export learner.py\n",
    "'''\n",
    "Class used for training a Pytorch neural network.\n",
    "'''\n",
    "\n",
    "import torch\n",
    "\n",
    "class Learner:\n",
    "    \"\"\"Class used for training a Pytorch neural network.\n",
    "    \n",
    "    The class is initialized with a CNN model, a loss function, an optimizer and train\n",
    "    and validation datasets. The main mehods are:\n",
    "    \n",
    "    fit(epochs) : train the network for the given number of epochs\n",
    "    pred(xb) : apply model to a batch\n",
    "    save_state() and load_state() : save and load learner state\n",
    "    get_history() : return the train and validation losses, accuracies and learning rates\n",
    "                    for each epoch\n",
    "                    \n",
    "    Note: the shape of the targets used for training and the prediction returned by pred() may \n",
    "    be different than the shape of the input tensor, depending on the model used. A center crop\n",
    "    is done on the tensors if the shapes of the tensor returned by the model and the target are different.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn\n",
    "        The neural network to be trained\n",
    "    loss_func : function\n",
    "        The function used for calculating the loss. Should have signature loss_func(input, \n",
    "        target, weight=None, epoch=None). `input` has shape (batch size, num classes, height, width)\n",
    "        and target has shape (batch size, height, width). `weight` can be used for weighting the loss \n",
    "        for each pixel (same shape as `target`) and `epoch` is the current training epoch. \n",
    "    optm : torch.optim\n",
    "        Optimizer used for updating the parameters\n",
    "    train_dl : torch.Dataset\n",
    "        Dataset used for training\n",
    "    valid_dl : torch.Dataset\n",
    "        Dataset used for validation\n",
    "    scheduler : torch.optim.lr_scheduler\n",
    "        Scheduler used for updating the learning rate of the optimizer\n",
    "    acc_funcs: dict\n",
    "        Dict of functions to be used for measuring result accuracy. Each key is a string containing\n",
    "        the name of the accuracy measure and respective values are functions with signature f(input, target)\n",
    "        containing the prediction of the model and the ground truth. Shapes of input and target are the same \n",
    "        as in `loss_func`     \n",
    "    main_acc_func : string\n",
    "        Accuracy score used for checking if the model has improved. At the end of each epoch, if this\n",
    "        accuracy is larger than any other previously recorded, the parameters of the model are saved\n",
    "    checkpoint_file : string\n",
    "        File to save the model when the accuracy have improved. Also used as default file for saving\n",
    "        the model when function save_state is called\n",
    "    scheduler_step_epoch : bool\n",
    "        If True, the scheduler will call step() after every epoch. If False, step() will be called after\n",
    "        every batch.\n",
    "    device : torch.device\n",
    "        Device used for training\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, loss_func, optm, train_dl, valid_dl, scheduler=None, \n",
    "                 acc_funcs=None, main_acc_func='loss', checkpoint_file='./learner.tar', \n",
    "                 scheduler_step_epoch=True, callbacks=None, device=None):\n",
    "        \n",
    "        if acc_funcs is None:\n",
    "            self.acc_funcs = {}\n",
    "        else:\n",
    "            self.acc_funcs = acc_funcs\n",
    "        if callbacks is None:\n",
    "            callbacks = []\n",
    "        if device is None:\n",
    "            if torch.cuda.is_available():\n",
    "                device = torch.device('cuda')\n",
    "            else:\n",
    "                device = torch.device('cpu')    \n",
    "            self.device = device\n",
    "        \n",
    "        self.model = model\n",
    "        self.loss_func = loss_func\n",
    "        self.optm = optm\n",
    "        self.train_dl = train_dl\n",
    "        self.scheduler = scheduler\n",
    "        self.valid_dl = valid_dl\n",
    "        self.callbacks = callbacks\n",
    "        self.device = device\n",
    "        self.main_acc_func = main_acc_func\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "        self.scheduler_step_epoch = scheduler_step_epoch\n",
    "        \n",
    "        self.train_loss_history = []\n",
    "        self.valid_loss_history = []\n",
    "        acc_funcs_history = {}\n",
    "        for k, v in acc_funcs.items():\n",
    "            acc_funcs_history[k] = []\n",
    "        self.acc_funcs_history = acc_funcs_history\n",
    "        \n",
    "        nb, nc, h, w = self.get_output_shape()\n",
    "        self.crop_shape = (h, w)\n",
    "                   \n",
    "        self.lr_history = []\n",
    "        self.epoch = 0\n",
    "        self.checkpoint = {}       # Will store best model found\n",
    "        self.best_score = None\n",
    "            \n",
    "    def fit(self, epochs):\n",
    "        '''Train model for the given number of epochs. Each epoch consists in \n",
    "        updating the weights for one pass in the training set and measuring loss\n",
    "        and accuracies for one pass in the validation set.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        epochs : int\n",
    "            Number of epochs for training\n",
    "        '''\n",
    "        \n",
    "        # Returns model, but it is not necessary to assign to new variable since the layers\n",
    "        # will be converted and copied to the GPU\n",
    "        self.model.to(self.device)\n",
    "        self._print_epoch_info_header()\n",
    "        for epoch in range(epochs):\n",
    "            self._fit_one_epoch()\n",
    "            self._print_epoch_info()\n",
    "            \n",
    "            self._check_if_better_score()\n",
    "            self.epoch += 1\n",
    "            \n",
    "         \n",
    "    def _fit_one_epoch(self):\n",
    "        '''Train model for one epoch. Also applies validation.\n",
    "        '''\n",
    "        \n",
    "        self._train_one_epoch()\n",
    "        self._validate_one_epoch()\n",
    "\n",
    "        if (self.scheduler is not None) and self.scheduler_step_epoch:\n",
    "            self.lr_history.append(self.scheduler.get_lr())\n",
    "            self.scheduler.step()\n",
    "\n",
    "    def _train_one_epoch(self):\n",
    "        '''Train model for one epoch.\n",
    "        '''\n",
    "        \n",
    "        self.model.train()\n",
    "        train_loss = 0.\n",
    "        for item_collection in self.train_dl:\n",
    "            loss = self._apply_to_batch(*item_collection)\n",
    "            loss.backward()\n",
    "            self.optm.step()\n",
    "            self.optm.zero_grad()\n",
    "            \n",
    "            if (self.scheduler is not None) and (not self.scheduler_step_epoch):\n",
    "                self.lr_history.append(self.scheduler.get_lr())\n",
    "                self.scheduler.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                train_loss += loss.item()\n",
    "                \n",
    "        self.train_loss_history.append(train_loss/len(self.train_dl))\n",
    "    \n",
    "    def _validate_one_epoch(self):\n",
    "        '''Validate the model for one epoch.\n",
    "        '''\n",
    "        \n",
    "        self.model.eval()\n",
    "        valid_loss = 0.\n",
    "        valid_acc = dict(zip(self.acc_funcs.keys(), [0.]*len(self.acc_funcs)))\n",
    "        with torch.no_grad():\n",
    "            for item_collection in self.valid_dl:\n",
    "                loss, predb, yb = self._apply_to_batch(*item_collection, ret_data=True)\n",
    "\n",
    "                valid_loss += loss.item()\n",
    "                accs = self._apply_acc_funcs(predb, yb)\n",
    "                for key in accs:\n",
    "                    valid_acc[key] += accs[key]\n",
    "            \n",
    "            self.valid_loss_history.append(valid_loss/len(self.valid_dl))\n",
    "            for idx, (func_name, acc_func) in enumerate(self.acc_funcs.items()):\n",
    "                self.acc_funcs_history[func_name].append(valid_acc[func_name]/len(self.valid_dl))\n",
    "                \n",
    "            for cb in self.callbacks:\n",
    "                cb.on_epoch_end(item_collection[0], item_collection[1], predb, self.epoch)\n",
    "        \n",
    "    def _apply_to_batch(self, xb, yb, wb=None, ret_data=False):\n",
    "        '''Given an input and target batch, and optionaly a loss weights batch, apply\n",
    "        the model to the data and calculates loss.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        xb : torch.Tensor\n",
    "            Input data\n",
    "        yb : torch.Tensor\n",
    "            Target data\n",
    "        wb : torch.Tensor\n",
    "            Weights for each pixel\n",
    "        ret_data : bool\n",
    "            If False, only returns loss. If True, also returns predictions and the cropped\n",
    "            target (in case the model returned a smaller output than the target)\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        loss : torch.float\n",
    "            The calculated loss\n",
    "        predb : torch.Tensor\n",
    "            The predictions of the model. Only returned if ret_data is True\n",
    "        yb_cropped : torch.Tensor\n",
    "            The target cropped with the same size as the values returned by the model. Only returned \n",
    "            if ret_data is True\n",
    "        '''\n",
    "        \n",
    "        device = self.device\n",
    "        xb, yb = xb.to(device, torch.float32), yb.to(device, torch.long)\n",
    "        if wb is None: \n",
    "            wb_cropped = None\n",
    "        else:\n",
    "            wb = wb.to(device, torch.float32)\n",
    "            wb_cropped = self.center_crop_tensor(wb.squeeze(1), (wb.shape[0],)+self.crop_shape)\n",
    "        predb = self.model(xb)\n",
    "        yb_cropped = self.center_crop_tensor(yb.squeeze(1), (yb.shape[0],)+self.crop_shape)\n",
    "        loss = self.loss_func(predb, yb_cropped, wb_cropped)\n",
    "        \n",
    "        if ret_data:\n",
    "            return loss, predb, yb_cropped\n",
    "        else:\n",
    "            return loss\n",
    "    \n",
    "    def _print_epoch_info_header(self):\n",
    "        '''Print table header shown during training'''\n",
    "        \n",
    "        print_str = f'{\"Epoch\":<7}{\"Train loss\":>15}{\"Valid loss\":>15}'\n",
    "        for func_name in self.acc_funcs:\n",
    "            print_str += f'{func_name:>15}'\n",
    "        print(print_str)\n",
    "        \n",
    "    def _print_epoch_info(self):\n",
    "        '''Print training and validation loss and accuracies calculated for the current epoch.'''\n",
    "        \n",
    "        print_str = f'{self.epoch:5}{self.train_loss_history[-1]:17.3f}{self.valid_loss_history[-1]:15.3f}'\n",
    "        for func_name in self.acc_funcs:\n",
    "            acc_func_h = self.acc_funcs_history[func_name]\n",
    "            print_str += f'{acc_func_h[-1]:15.3f}'\n",
    "        print(print_str)\n",
    "        \n",
    "    def _apply_acc_funcs(self, predb, yb):\n",
    "        '''Apply each accuracy function to the data. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        predb : torch.Tensor\n",
    "            The model predictions\n",
    "        yb : torch.Tensor\n",
    "            The target\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        valid_acc : list\n",
    "            List containing the accuracy calculated by each function\n",
    "        '''\n",
    "        \n",
    "        valid_acc = {}\n",
    "        for idx, (func_name, acc_func) in enumerate(self.acc_funcs.items()):\n",
    "            valid_acc[func_name] = acc_func(predb, yb)\n",
    "        return valid_acc\n",
    "    \n",
    "    def _check_if_better_score(self):\n",
    "        '''Check if the value of the main accuracy function has improved. If True,\n",
    "        the model is saved in the file given by self.checkpoint_file.'''\n",
    "        \n",
    "        score_improved = False\n",
    "        prev_score = self.best_score\n",
    "\n",
    "        if self.main_acc_func=='loss':\n",
    "            score = self.valid_loss_history[-1]\n",
    "            if (prev_score is None) or (score < prev_score):\n",
    "                score_improved = True\n",
    "        else:\n",
    "            score = self.acc_funcs_history[self.main_acc_func][-1]\n",
    "            if (prev_score is None) or (score > prev_score):\n",
    "                score_improved = True\n",
    "\n",
    "        if score_improved:\n",
    "            #print(f'Score improved from {prev_score} to {score} checkpoint saved')\n",
    "            self.best_score = score\n",
    "            self.update_checkpoint()\n",
    "            self.save_state(True)\n",
    "            \n",
    "    def get_state_dict(self):\n",
    "        '''Returns dictionary containing all relevant information about this class.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        state_dict : dict\n",
    "            Dictionary containing relevant class attributes\n",
    "        '''\n",
    "\n",
    "        state_dict = {\n",
    "                        'model_state' : self.model.state_dict(),\n",
    "                        'optm_state' : self.optm.state_dict(),\n",
    "                        'scheduler_state' : self.scheduler.state_dict(),\n",
    "                        'epoch' : self.epoch,\n",
    "                        'best_score' : self.best_score,\n",
    "                        'model' : str(self.model),\n",
    "                        'train_loss_history' : self.train_loss_history,\n",
    "                        'valid_loss_history' : self.valid_loss_history,\n",
    "                        'acc_funcs_history' : self.acc_funcs_history\n",
    "                     }\n",
    "        \n",
    "        return state_dict\n",
    "        \n",
    "    def update_checkpoint(self):\n",
    "        '''Updates chekpoint of the model using current parameters.'''\n",
    "        \n",
    "        self.checkpoint = self.get_state_dict()\n",
    "            \n",
    "    def save_state(self, checkpoint=False, filename=None):\n",
    "        '''Saves all the relevant information about this class. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        checkpoint : bool\n",
    "            If True, saves the parameters associated with the best model found during training, that is,\n",
    "            the model providing the largest value of function acc_funcs[main_acc_func]. If False, saves\n",
    "            the current parameters of the model.\n",
    "        filename : string\n",
    "            Filename to save the information. If None, it is given by self.checkpoint_file \n",
    "        '''\n",
    "        \n",
    "        if filename is None:\n",
    "            filename = self.checkpoint_file\n",
    "        \n",
    "        if checkpoint:\n",
    "            torch.save(self.checkpoint, filename)\n",
    "        else:\n",
    "            torch.save(self.get_state_dict(), filename)\n",
    "        \n",
    "    def load_state(self, filename=None):\n",
    "        '''Loads all the relevant information about this class from a file. Attributes of the\n",
    "        class are updated with the information read.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : string\n",
    "            Filename to load the information. If None, it is given by self.checkpoint_file \n",
    "        '''\n",
    "        \n",
    "        if filename is None:\n",
    "            filename = self.checkpoint_file\n",
    "        \n",
    "        checkpoint = torch.load(filename)\n",
    "        self.model.load_state_dict(checkpoint['model_state'])\n",
    "        self.optm.load_state_dict(checkpoint['optm_state'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "        self.epoch = checkpoint['epoch']\n",
    "        self.train_loss_history = checkpoint['train_loss_history']\n",
    "        self.valid_loss_history = checkpoint['valid_loss_history']\n",
    "        self.acc_funcs_history = checkpoint['acc_funcs_history']\n",
    "        self.best_score = checkpoint['best_score']\n",
    "        self.checkpoint = checkpoint\n",
    "    \n",
    "    def pred(self, xb, yb=None, return_classes=False):\n",
    "        '''Apply model to a batch, model parameters are not updated. \n",
    "        \n",
    "        If `y` is provided, also returns the accuracy of the prediction for the\n",
    "        given target.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        xb : torch.Tensor\n",
    "            Input of the model. Must have shape (batch size, channels, height, width)\n",
    "        yb : torch.Tensor\n",
    "            The target. Must have shape (batch size, 1, height, width)\n",
    "        return_classes : bool\n",
    "            If True, returns classes instead of probabilities. Also returns accuracy of \n",
    "            the prediction\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        predb : torch.Tensor\n",
    "            The predicted class probabilities. Only returned if `return_classes` is False\n",
    "        bin_predb : torch.Tensor\n",
    "            The predicted segmentation. Returned in place of `predb` if `return_classes` is True\n",
    "        predb_acc : float\n",
    "            Accuracies calculated for functions self.acc_funcs. Only returned if `yb` is True        \n",
    "        '''\n",
    "        # TODO: Implement TTA augmentation\n",
    "        \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            xb = xb.to(self.device, torch.float32)\n",
    "            predb = self.model(xb)\n",
    "\n",
    "            if return_classes:\n",
    "                classes_predb = torch.argmax(predb, dim=1).to('cpu', torch.uint8)\n",
    "  \n",
    "            if yb is None:\n",
    "                if return_classes:\n",
    "                    return classes_predb, None\n",
    "                else:\n",
    "                    return predb, None\n",
    "            else:\n",
    "                yb = yb.to(self.device, torch.long)\n",
    "                yb_cropped = self.center_crop_tensor(yb.squeeze(1), (xb.shape[0],)+self.crop_shape)\n",
    "                   \n",
    "                predb_acc = self._apply_acc_funcs(predb, yb_cropped)\n",
    "                \n",
    "                if return_classes:\n",
    "                    return classes_predb, predb_acc\n",
    "                else:\n",
    "                    return predb, predb_acc\n",
    "                \n",
    "    def test(self, test_dl):\n",
    "        '''Calculate accuracies for a dataset. Calculated accuracies are given by the functions\n",
    "        in self.acc_funcs.\n",
    "          \n",
    "        Parameters\n",
    "        ----------\n",
    "        test_dl : torch.Dataset\n",
    "            The input dataset. Usually a dataset used for the testing phase. \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of calculated accuracies in the same order as the functions stored in self.acc_funcs\n",
    "        '''\n",
    "        \n",
    "        test_acc = [0.]*len(self.acc_funcs)\n",
    "        with torch.no_grad():\n",
    "            for xb,yb in test_dl:\n",
    "                _, pred_acc = self.pred(xb, yb)\n",
    "                for idx, (k,v) in enumerate(pred_acc.items()):\n",
    "                    test_acc[idx] += v\n",
    "                    \n",
    "        return [v/len(test_dl) for v in test_acc]\n",
    "           \n",
    "    def get_output_shape(self):\n",
    "        '''Calculate the output shape of the model from one of the items in the dataset.\n",
    "              \n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            Shape of the output from the model\n",
    "        '''\n",
    "        \n",
    "        xb, *_ = next(iter(self.train_dl))\n",
    "        \n",
    "        self.model.to(self.device)\n",
    "        xb = xb.to(self.device)\n",
    "        with torch.no_grad():\n",
    "            pred = self.model(xb)\n",
    "        self.model.to('cpu')\n",
    "                \n",
    "        return pred.shape\n",
    "\n",
    "    @staticmethod\n",
    "    def center_crop_tensor(tensor, out_shape):\n",
    "        '''Center crop a tensor without copying its contents.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor : torch.Tensor\n",
    "            The tensor to be cropped\n",
    "        out_shape : tuple\n",
    "            Desired shape\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        tensor : torch.Tensor\n",
    "            A new view of the tensor with shape out_shape\n",
    "        '''\n",
    "\n",
    "        out_shape = torch.tensor(out_shape)\n",
    "        tensor_shape = torch.tensor(tensor.shape)\n",
    "        shape_diff = (tensor_shape - out_shape)//2\n",
    "\n",
    "        for dim_idx, sd in enumerate(shape_diff):\n",
    "            tensor = tensor.narrow(dim_idx, sd, out_shape[dim_idx])\n",
    "\n",
    "        return tensor\n",
    "    \n",
    "    @staticmethod\n",
    "    def center_expand_tensor(self, tensor, out_shape):\n",
    "        '''Center expand a tensor. Assumes `tensor` is not larger than `out_shape`\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        tensor : torch.Tensor\n",
    "            The tensor to be expanded\n",
    "        out_shape : tuple\n",
    "            Desired shape\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            A new tensor with shape out_shape\n",
    "        '''\n",
    "        \n",
    "        out_shape = torch.tensor(out_shape)\n",
    "        tensor_shape = torch.tensor(tensor.shape)\n",
    "        shape_diff = (out_shape - tensor_shape)\n",
    "\n",
    "        pad = []\n",
    "        for dim_idx, sd in enumerate(shape_diff.flip(0)):\n",
    "            if sd%2==0:\n",
    "                pad += [sd//2, sd//2]\n",
    "            else:\n",
    "                pad += [sd//2, sd//2+1]\n",
    "        \n",
    "        return F.pad(tensor, pad)\n",
    "    \n",
    "    def get_history(self):\n",
    "        '''Return the recorded history for some parameters and evaluations of this learner.\n",
    "        Returned values are:\n",
    "        train_loss : the training loss\n",
    "        valid_loss : the validation loss\n",
    "        acc : accuracies calculated for functions stored in self.acc_funcs\n",
    "        lr : learning rate\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        history : dict\n",
    "            Dictionary keyed by the name of the property.\n",
    "        '''\n",
    "        \n",
    "        history = {\n",
    "                    'train_loss':self.train_loss_history,\n",
    "                    'valid_loss':self.valid_loss_history,\n",
    "                    'acc':self.acc_funcs_history,\n",
    "                    'lr':self.lr_history\n",
    "        }\n",
    "        return history\n",
    "    \n",
    "    def reset_history(self):\n",
    "        '''Reset the history for this learner\n",
    "        '''\n",
    "        \n",
    "        self.train_loss_history = []\n",
    "        self.valid_loss_history = []\n",
    "        acc_funcs_history = {}\n",
    "        for k, v in self.acc_funcs.items():\n",
    "            acc_funcs_history[k] = []\n",
    "        self.acc_funcs_history = acc_funcs_history     \n",
    "        \n",
    "    def reset_training(self, optm, scheduler):\n",
    "        '''Reset parameters and history for this learner. Notice that this does not reset optimizer and scheduler\n",
    "        parameters!\n",
    "        '''\n",
    "        \n",
    "        # TODO: verify if optimizer.state=collections.defaultdict(dict) would work for resetting optimizer\n",
    "        self.model.reset_parameters()     # Will probably not work for fastai model\n",
    "        self.reset_history()     \n",
    "        \n",
    "    def set_optimizer(self, optm):\n",
    "        '''Set or update optimizer.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        optm : torch.optim.Optimizer\n",
    "            New optimizer\n",
    "        '''\n",
    "        \n",
    "        self.optm = optm\n",
    "\n",
    "    def set_scheduler(self, scheduler):\n",
    "        '''Set or update the learning rate scheduler.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        optm : torch.optim.lr_scheduler._LRScheduler\n",
    "            New scheduler\n",
    "        '''\n",
    "        \n",
    "        self.scheduler = scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
