{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image transformation routines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Converted transforms.py to E:\\Dropbox\\deep learning\\pytorch\\pytorchlb\\pytorchlb\\transforms.py\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Export cells\n",
    "#!python notebook2script.py transforms.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformations and data augmentation\n",
    "#export transforms.py\n",
    "'''\n",
    "Image transformation routines\n",
    "'''\n",
    "\n",
    "import imgaug as ia\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as torch_transforms\n",
    "import cv2\n",
    "\n",
    "def to_tensor(img, is_label=False):\n",
    "    '''Transform PIL.Image or numpy array to a tensor. Most of the\n",
    "    function was taken from torchvision.transforms.functional.to_tensor.\n",
    "    \n",
    "    Note 1: Intensities are reescaled to [0, 1] if is_label is False and `img`\n",
    "    is of type uint8. Use is_label=True if you do not want to reescale image \n",
    "    (even if it is not a label).\n",
    "    \n",
    "    Note 2: The image is expected to have size (height, width) or (height, width, channels).\n",
    "    Returns image with size (channels, height, width).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : PIL.Image or np.ndarray\n",
    "        The input image\n",
    "    is_label : bool\n",
    "        If True, images is not reescaled\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    img : torch.Tensor\n",
    "        The output image as a tensor\n",
    "    '''\n",
    "\n",
    "    if isinstance(img, np.ndarray):\n",
    "        # handle numpy array\n",
    "        if img.ndim == 2:\n",
    "            img = img[:, :, None]\n",
    "\n",
    "        img = torch.from_numpy(img.transpose((2, 0, 1)))\n",
    "        # backward compatibility\n",
    "        if isinstance(img, torch.ByteTensor) and not is_label:\n",
    "            return img.float().div(255)\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    # handle PIL Image\n",
    "    if img.mode == 'I':\n",
    "        img = torch.from_numpy(np.array(img, np.int32, copy=False))\n",
    "    elif img.mode == 'I;16':\n",
    "        img = torch.from_numpy(np.array(img, np.int16, copy=False))\n",
    "    elif img.mode == 'F':\n",
    "        img = torch.from_numpy(np.array(img, np.float32, copy=False))\n",
    "    elif img.mode == '1':\n",
    "        img = 255 * torch.from_numpy(np.array(img, np.uint8, copy=False))\n",
    "    else:\n",
    "        img = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n",
    "    # PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\n",
    "    if img.mode == 'YCbCr':\n",
    "        nchannel = 3\n",
    "    elif img.mode == 'I;16':\n",
    "        nchannel = 1\n",
    "    else:\n",
    "        nchannel = len(img.mode)\n",
    "    img = img.view(img.size[1], img.size[0], nchannel)\n",
    "    # put it from HWC to CHW format\n",
    "    img = img.transpose(0, 1).transpose(0, 2).contiguous()\n",
    "    if isinstance(img, torch.ByteTensor) and not is_label:\n",
    "        return img.float().div(255)\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "def tensor_2_pil(tensor):\n",
    "    '''Transform torch.Tensor to a PIL image.\n",
    "    \n",
    "    Note: Intensities are reescaled to [0, 255] if tensor is of type float. Values\n",
    "    are not changed if the tensor is of type int.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : torch.Tensor\n",
    "        The input tensor\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    PIL.Image\n",
    "        The output PIL image\n",
    "    '''\n",
    "\n",
    "    return torch_transforms.ToPILImage()(tensor)\n",
    "\n",
    "\n",
    "def pil_to_imgaug(img, label=None, weight=None):\n",
    "    '''Transform PIL images to corresponding objects of the imgaug (image augmentation)\n",
    "    module.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : PIL.Image\n",
    "        PIL image, only tested for uint8 type\n",
    "    label : PIL.Image\n",
    "        Label, must contain integer values. Converted to a imgaug.SegmentationMapsOnImage object\n",
    "    weight : PIL.Image\n",
    "        Weight, converted to a imgaug.HeatmapsOnImage object\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ret_vals : list\n",
    "        List containing imgaug images corresponding to the `img`, `label` and `weight` inputs\n",
    "    '''    \n",
    "\n",
    "    img_shape = img.size[::-1]\n",
    "    ret_vals = [np.array(img)]\n",
    "    if label is not None:\n",
    "        segmap = ia.SegmentationMapsOnImage(np.array(label), img_shape)\n",
    "        ret_vals.append(segmap)\n",
    "    if weight is not None:\n",
    "        heatmap = ia.HeatmapsOnImage(np.array(weight), img_shape)\n",
    "        ret_vals.append(heatmap)\n",
    "        \n",
    "    return ret_vals\n",
    "\n",
    "def imgaug_to_tensor(img=None, label=None, weight=None):\n",
    "    '''Transform imgaug (image augmentation) images to torch tensors.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img : np.ndarray\n",
    "        Image to be transformed\n",
    "    label : imageaug.SegmentationMapsOnImage\n",
    "        Label image\n",
    "    weight : imageaug.HeatmapsOnImage\n",
    "        Weight image\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ret_vals : list\n",
    "        torch tensors corresponding to the `img`, `label` and `weight` inputs\n",
    "    '''  \n",
    "    \n",
    "    ret_vals = []\n",
    "    if img is not None:\n",
    "        ret_vals.append(to_tensor(img))\n",
    "    if label is not None:\n",
    "        ret_vals.append(to_tensor(label.get_arr(), True))\n",
    "    if weight is not None:\n",
    "        ret_vals.append(to_tensor(weight.get_arr()))\n",
    "    \n",
    "    return ret_vals\n",
    "\n",
    "def translate_imagaug_seq(imgaug_seq):\n",
    "    '''Closure for translating arguments 'image', 'segmentation_maps' and 'heatmaps' of \n",
    "    imgaug functions to 'img', 'label' and 'weight'\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imgaug_seq : function or class\n",
    "        imgaug function or class to be translated. Usually, it is an imgaug.Sequential\n",
    "        class\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    transf_imgaug_seq : function\n",
    "        New function with translated arguments\n",
    "    '''  \n",
    "    \n",
    "    def transf_imgaug_seq(img, label=None, weight=None, **kwargs):\n",
    "        return imgaug_seq(image=img, segmentation_maps=label, heatmaps=weight, **kwargs)\n",
    "    \n",
    "    return transf_imgaug_seq\n",
    "        \n",
    "def pil_to_imgaug_to_tensor(imgaug_seq):\n",
    "    '''Utility function for generating a typical transfromation pipeline: \n",
    "    pil image -> imgaug -> tensor\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    imgaug_seq : function or class\n",
    "        imgaug function or class to be translated. Usually, it is an imgaug.Sequential\n",
    "        class\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    transform_funcs : list\n",
    "        List of transformations\n",
    "    '''  \n",
    "    \n",
    "    transf_pil_to_imgaug = pil_to_imgaug\n",
    "    transf_imgaug = translate_imagaug_seq(imgaug_seq)\n",
    "    transf_imgaug_to_tensor = imgaug_to_tensor\n",
    "    transform_funcs = [transf_pil_to_imgaug, transf_imgaug, transf_imgaug_to_tensor]\n",
    "    \n",
    "    return transform_funcs\n",
    "    \n",
    "def clahe(pil_img, clip_limit=2.0, tile_shape=(8, 8)):\n",
    "    '''Contrast Limited Adaptive Histogram Equalization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    pil_img : PIL.Image\n",
    "        Image to be transformed\n",
    "    clip_limit : float\n",
    "        Threshold value for contrast limiting\n",
    "    tile_shape : 2-tuple\n",
    "        Tuple setting the tile size for the method\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    out_pil_img : PIL.Image\n",
    "        Output image\n",
    "    '''  \n",
    "    \n",
    "    np_img = np.array(pil_img).astype(np.uint8)\n",
    "    enhancer = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_shape)\n",
    "    if np_img.ndim == 2:\n",
    "        np_img = enhancer.apply(np_img)\n",
    "    elif np_img.ndim == 3:\n",
    "        np_img[:, :, 0] = enhancer.apply(np_img[:, :, 0])\n",
    "        np_img[:, :, 1] = enhancer.apply(np_img[:, :, 1])\n",
    "        np_img[:, :, 2] = enhancer.apply(np_img[:, :, 2])\n",
    "        \n",
    "    out_pil_img = Image.fromarray(np_img)\n",
    "    return out_pil_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
